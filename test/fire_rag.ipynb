{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5855ef-b555-4499-a0e9-e04d2e260caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72da4049-cffb-4a25-ac53-a5e226b4fefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b13fe0d5a504e9fa30601709584f460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a6c06e387447a1b3d61c84a4c8cfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a80d046a41437680a57e943de2946c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf0f9d30fc14d9690d65e29f60a6b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9af97beaa42410e93ba3bf5f262e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f80a2007614c05826e70f26d99c2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42bd7c1b55341c1b17ee25a1014cef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/contriever')\n",
    "model = AutoModel.from_pretrained('facebook/contriever')\n",
    "\n",
    "sentences = [\n",
    "    \"Where was Marie Curie born?\",\n",
    "    \"Maria Sklodowska, later known as Marie Curie, was born on November 7, 1867.\",\n",
    "    \"Born in Paris on 15 May 1859, Pierre Curie was the son of Eugène Curie, a doctor of French Catholic origin from Alsace.\"\n",
    "]\n",
    "\n",
    "# Apply tokenizer\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Mean pooling\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings\n",
    "embeddings = mean_pooling(outputs[0], inputs['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb42c36a-7b65-45db-8507-9e11e67fa070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de8451d-062c-438b-9375-edf962ab87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name facebook/contriever. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"facebook/contriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a2d375-49a0-435b-abde-a135aabf149c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e080c9a4e2af41eba03f76ec137f6039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fd55ec2c82463d9317f91991342524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22c0dc029594b4b916658e70463a7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2559ddf6349f4c9db896d7278da5e462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76038ab4c91e47cd95331834ba8ec045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75503836f5640079cc42cd3e9692d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar modelo de embedding\n",
    "# https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "# Requires transformers>=4.51.0\n",
    "# Requires sentence-transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-4B\")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving,\n",
    "# together with setting `padding_side` to \"left\":\n",
    "# model = SentenceTransformer(\n",
    "#     \"Qwen/Qwen3-Embedding-4B\",\n",
    "#     model_kwargs={\"attn_implementation\": \"flash_attention_2\", \"device_map\": \"auto\"},\n",
    "#     tokenizer_kwargs={\"padding_side\": \"left\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ac1f1b1-0009-4587-9560-eb1e49f5401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = model.encode(\"What is the capital of China?\", prompt_name=\"query\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"scifact\",\n",
    "    vectors_config=VectorParams(size=len(query_embedding), distance=Distance.COSINE), ##DOT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9e260d2-4ea4-47d0-a89f-35842c15df52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client.delete_collection(collection_name=\"scifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f6a4c0-9351-4cfa-a8b5-642eda0ce9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ab758695504869af1652f12fa41a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "#### Descarga el dataset SciFact en la carpeta `datasets/scifact`\n",
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scifact.zip\"\n",
    "out_dir = \"datasets\"\n",
    "\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64d7cad1-0cfb-4460-951e-5a8ac092f6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5183"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04f06420-07fb-4084-a5bc-bb4151898e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from qdrant_client.models import PointStruct\n",
    "import math\n",
    "\n",
    "def insert_documents(json_data, batch_size=100):\n",
    "    all_doc_items = list(json_data.items())\n",
    "    total_batches = math.ceil(len(all_doc_items) / batch_size)\n",
    "\n",
    "    for i in tqdm(range(total_batches), desc=\"Insertando documentos en lotes\"):\n",
    "        batch = all_doc_items[i * batch_size : (i + 1) * batch_size]\n",
    "        points = []\n",
    "\n",
    "        for doc_id, contenido in batch:\n",
    "            vector = model.encode(contenido['text'])  # vector del abstract\n",
    "            payload = {\n",
    "                'doc_id': doc_id,\n",
    "                'title': contenido['title'],\n",
    "                'text': contenido['text']\n",
    "            }\n",
    "            points.append(\n",
    "                PointStruct(id=int(doc_id), vector=vector, payload=payload)\n",
    "            )\n",
    "\n",
    "        client.upsert(collection_name=\"scifact\", points=points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21a0f956-9dd5-4763-8094-a8fd5876ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertando documentos en lotes: 100%|████| 52/52 [21:51<00:00, 25.21s/it]\n"
     ]
    }
   ],
   "source": [
    "insert_documents(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b64eecf-9a20-4f4f-8ec6-67e5d163a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear funcion para recuperar\n",
    "def recuperar_documentos(query_text, top_k=10):\n",
    "    query_embeddings = model.encode(query_text, prompt_name=\"query\") \n",
    "    search_result = client.query_points(\n",
    "        collection_name=\"scifact\",\n",
    "        query=query_embeddings,\n",
    "        with_payload=True,\n",
    "        limit=top_k\n",
    "    ).points\n",
    "    return search_result\n",
    "\n",
    "\"\"\"\n",
    "qrels = {\n",
    "    \"q1\" : {\"doc1\": 1},\n",
    "    \"q2\" : {\"doc2\": 1},\n",
    "}\n",
    "\"\"\"\n",
    "def format_result(rel_docs):\n",
    "    docs_inference={}\n",
    "    for doc in rel_docs:\n",
    "        doc_id = str(doc.id)\n",
    "        score = doc.score\n",
    "        docs_inference[doc_id] = score\n",
    "    return docs_inference\n",
    "\n",
    "def get_final_format(queries):\n",
    "    results = {}\n",
    "    for qid, query_text in tqdm(queries.items(), desc=\"obteniendo resultados\"):\n",
    "        rel_docs = recuperar_documentos(query_text)\n",
    "        results[qid] = format_result(rel_docs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab4cbe33-f30a-4d03-adfa-34e13e50470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "obteniendo resultados: 100%|███████████| 300/300 [00:27<00:00, 10.82it/s]\n"
     ]
    }
   ],
   "source": [
    "resultados = get_final_format(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e77e5417-622f-412b-a0ef-4c5ecaf9dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(resultados, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3ea5641-4598-4ef4-a83d-f3ee4ab4ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5768e32-b1f9-4df0-8aa0-2d16eddafdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'NDCG@1': 0.64667, 'NDCG@3': 0.7162, 'NDCG@5': 0.75226, 'NDCG@10': 0.77172}, {'MAP@1': 0.61606, 'MAP@3': 0.68817, 'MAP@5': 0.71354, 'MAP@10': 0.72414}, {'Recall@1': 0.61606, 'Recall@3': 0.76289, 'Recall@5': 0.85228, 'Recall@10': 0.90667}, {'P@1': 0.64667, 'P@3': 0.27889, 'P@5': 0.19133, 'P@10': 0.10333})\n"
     ]
    }
   ],
   "source": [
    "from beir import util\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "# Cargar qrels y resultados\n",
    "import json\n",
    "\n",
    "# with open(\"qrels/qrels.json\") as f:\n",
    "#     qrels = json.load(f)\n",
    "\n",
    "# with open(\"results/results.json\") as f:\n",
    "#     results = json.load(f)\n",
    "\n",
    "retriever = EvaluateRetrieval()\n",
    "metrics = retriever.evaluate(qrels, resultados, k_values=[1, 3, 5, 10])\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543edd93-95ac-4a3a-9c17-4b102cada814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un pseudo query y testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca08c0b-18b7-446d-a175-de223088f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear multiples pseudo documentos y probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83092d59-d10b-44af-a629-8b041af08bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar documentos y crear psudocumento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ac2a5-53f3-402b-985c-d001789e1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar con multiples documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fd60865-51d1-4df3-86a2-8121cb48f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d22c3-d60e-480d-a5ec-10b45819e1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

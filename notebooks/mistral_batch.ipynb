{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9da71ab-fd1d-413c-bea7-9d3bb68b47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_request(request_id, prompt, n=3, temperature=0.7, max_tokens=512):\n",
    "    \"\"\"\n",
    "    Crea un diccionario de solicitud con el formato deseado para un archivo JSONL.\n",
    "\n",
    "    Args:\n",
    "        request_id (str): Un identificador único para la solicitud.\n",
    "        prompt (str): El contenido del mensaje del usuario.\n",
    "        n (int): El número de respuestas a generar.\n",
    "        temperature (float): El valor de temperatura para la generación de texto.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario con el formato de solicitud.\n",
    "    \"\"\"\n",
    "    request = {\n",
    "        \"custom_id\": str(request_id),  # Asegura que sea un string\n",
    "        \"body\": {\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"n\": n,\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "    }\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340c1819-9938-443e-b45d-c3c6c82318d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdir_src.sota.hyde import HyDE, Promptor\n",
    "from kdir_src.generators.mistral_ai import MistralGenerator\n",
    "from kdir_src.models.all_models import load_models, get_query_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e9b54b-ba52-40c0-a857-d6d645dde152",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'jTrxtC1mqMP1Lj9aMg8fvexSh2xDgZC4'\n",
    "dataset_name = 'arguana'\n",
    "promptor = Promptor(dataset_name)\n",
    "generator = MistralGenerator('mistral-small-2503', KEY, 3)\n",
    "#encoder_models = load_models()\n",
    "hyde = HyDE(dataset_name, promptor, generator, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d8ff54-c36f-463b-875c-1b9f112f568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdir_src.dataset.beir import get_sentences_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3cb49b-c51f-4c3d-a308-5235e21eca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5fc353c827452ea67aa07ce850db29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando queries: 100%|██████████████████████████████████████████████████████| 1406/1406 [00:00<00:00, 2043378.87it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences, queries_ids = get_sentences_queries(dataset_name)\n",
    "requests = []\n",
    "for i, query in enumerate(sentences):\n",
    "    prompt = hyde.prompt(query)\n",
    "    req = create_request(queries_ids[i], prompt)\n",
    "    requests.append(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc7abea-ccbb-43b6-85fb-063b78832f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'requests.jsonl' creado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo JSONL\n",
    "output_filename = \"requests.jsonl\"\n",
    "\n",
    "# Escribir las solicitudes en el archivo JSONL\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    for req in requests:\n",
    "        # json.dumps convierte el diccionario en una cadena JSON\n",
    "        # ensure_ascii=False permite caracteres no ASCII (como tildes)\n",
    "        f.write(json.dumps(req, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Archivo '{output_filename}' creado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c63b8d-643d-4721-9a6b-b9579af07e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import os\n",
    "\n",
    "api_key = 'jTrxtC1mqMP1Lj9aMg8fvexSh2xDgZC4'\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "batch_data = client.files.upload(\n",
    "    file={\n",
    "        \"file_name\": \"requests.jsonl\",\n",
    "        \"content\": open(\"requests.jsonl\", \"rb\")\n",
    "    },\n",
    "    purpose = \"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2e55d1-f027-4ec3-871d-9047a2e04ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d9d6ad4d-785c-4a63-bc05-efbf1783abec'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c318599a-3033-4f4f-8e2f-6514cd93e3c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SDKError",
     "evalue": "API error occurred: Status 402\n{\"detail\": \"You cannot launch batch jobs this big with your free trial. Reduce the number of steps in your configuration or subscribe via the console.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m created_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral-small-2503\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjob_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtesting_hyde\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local1/ronaldinho/enviroments/env_kdir/lib/python3.10/site-packages/mistralai/mistral_jobs.py:325\u001b[0m, in \u001b[0;36mMistralJobs.create\u001b[0;34m(self, input_files, endpoint, model, metadata, timeout_hours, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    324\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mSDKError(\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m, http_res\u001b[38;5;241m.\u001b[39mstatus_code, http_res_text, http_res\n\u001b[1;32m    327\u001b[0m     )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    329\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n",
      "\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 402\n{\"detail\": \"You cannot launch batch jobs this big with your free trial. Reduce the number of steps in your configuration or subscribe via the console.\"}"
     ]
    }
   ],
   "source": [
    "created_job = client.batch.jobs.create(\n",
    "    input_files=[batch_data.id],\n",
    "    model=\"mistral-small-2503\",\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    metadata={\"job_type\": \"testing_hyde\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edda1f-3fce-4eb5-a1aa-d9fabee26e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

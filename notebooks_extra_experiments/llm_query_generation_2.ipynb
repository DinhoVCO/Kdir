{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca287872",
   "metadata": {},
   "source": [
    "# Input Prompt for RFG \n",
    "\n",
    "We generate the input prompt to create the pseudo-documents, pseudo-queries, and pseudo-responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ceebc3",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5c922",
   "metadata": {},
   "source": [
    "## llama3-1-405b-instruct-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f85a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FXO0\\AppData\\Local\\miniforge3\\envs\\kdir_envi\\lib\\site-packages\\beir\\util.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "100%|██████████| 3633/3633 [00:00<00:00, 74965.35it/s]\n",
      "Procesando queries: 100%|██████████| 323/323 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 previously generated documents in '../doc_gen/fire/llama3-1-405b-instruct-v1/bge_large/llama3-1-405b-instruct-v1_generated_documents_nfcorpus.jsonl'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries (generate or skip): 323it [54:10, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document generation complete. Results saved in: ../doc_gen/fire/llama3-1-405b-instruct-v1/bge_large/llama3-1-405b-instruct-v1_generated_documents_nfcorpus.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from kdir_src.generators.lite_llm import LiteLLMGenerator\n",
    "from kdir_src.fire.Fire import Fire\n",
    "from kdir_src.fire.promptor_fire import Promptor_fire\n",
    "dataset_name='nfcorpus'\n",
    "model='llama3-1-405b-instruct-v1'\n",
    "promptor = Promptor_fire(dataset_name)\n",
    "generator = LiteLLMGenerator(model, 1, 512, 0.0)\n",
    "fire_rag = Fire(dataset_name, promptor, generator, None)\n",
    "fire_rag.generate_openai_doc_and_save_prf(model,'../input_prompt/fire/input_prompt.json',f'../doc_gen/fire/{model}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6367ffe",
   "metadata": {},
   "source": [
    "## llama3-2-11b-instruct-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddfedcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 16688.71it/s]\n",
      "Procesando queries: 100%|██████████| 323/323 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 previously generated documents in '../doc_gen/fire/llama3-2-11b-instruct-v1/bge_large/llama3-2-11b-instruct-v1_generated_documents_nfcorpus.jsonl'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries (generate or skip): 323it [13:19,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document generation complete. Results saved in: ../doc_gen/fire/llama3-2-11b-instruct-v1/bge_large/llama3-2-11b-instruct-v1_generated_documents_nfcorpus.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from kdir_src.generators.lite_llm import LiteLLMGenerator\n",
    "from kdir_src.fire.Fire import Fire\n",
    "from kdir_src.fire.promptor_fire import Promptor_fire\n",
    "dataset_name='nfcorpus'\n",
    "model='llama3-2-11b-instruct-v1'\n",
    "promptor = Promptor_fire(dataset_name)\n",
    "generator = LiteLLMGenerator(model, 1, 512, 0.0)\n",
    "fire_rag = Fire(dataset_name, promptor, generator, None)\n",
    "fire_rag.generate_openai_doc_and_save_prf(model,'../input_prompt/fire/input_prompt.json',f'../doc_gen/fire/{model}/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdir_envi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
